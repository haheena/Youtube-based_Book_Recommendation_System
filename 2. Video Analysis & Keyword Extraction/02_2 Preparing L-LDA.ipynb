{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37177e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
    "%cd Mecab-ko-for-Google-Colab\n",
    "!bash install_mecab-ko_on_colab_light_220429.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efdb4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from konlpy.tag import Mecab\n",
    "import pickle\n",
    "mecab = Mecab()\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '경로')  # 적절한 경로로 변경\n",
    "\n",
    "import model.labeled_lda as llda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ed7ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KDC 100번대 책들의 소개 부분을 토큰화하여 단어로 저장\n",
    "sentences = data100['Descript']\n",
    "word_list_100 = []\n",
    "for i,sentence in enumerate(sentences):\n",
    "    mecab = Mecab()\n",
    "    for word in mecab.pos(sentence, join=True):\n",
    "        if word.split(\"/\")[1] in ['NNP', 'NNG','VV'] and word.split(\"/\")[0] not in stopwords_k :\n",
    "            word_list_100.append(word.split(\"/\")[0])\n",
    "\n",
    "with open(\"워드리스트 저장할 위치/word_list_100\", \"wb\") as f:\n",
    "  pickle.dump(word_list_100, f)\n",
    "\n",
    "#이 방식으로 800번대까지 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4222ac89",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('word_list_100_re', 'rb') as f:\n",
    "    word_list_100 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487ab9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_k = ['은','는','아','음','제가','저는','여러분','예','안','전','얘','휴','유','박','거','것','어','속','나','을','를','게','우','에','의','이','가', '이','때','오','우'\n",
    "                          '으로','음악','로','에게','에서','까지','께','저','도','한','그리고', '제가'\n",
    "                          '로써','로서','지금','이제','으로써','다','등','등등','들','제','까지','좀','사실',\n",
    "                          '조금','몇','하면','수','와','과','왜','나','그','때','어느','그',\n",
    "                          '하다','네','뭐','석','것','만큼','진짜', '마찬가지', \"아\", \"그냥\",\n",
    "                          \"이\",\"등\", '그', \"아이고\", \"우리\", \"저희\", \"따라\",\"하다\",\"것\", \"의해\",'이제']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bf1de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "word100 = ' '.join(word_list_100)\n",
    "word200 = ' '.join(word_list_200)\n",
    "word300 = ' '.join(word_list_300)\n",
    "word400 = ' '.join(word_list_400)\n",
    "word500 = ' '.join(word_list_500)\n",
    "word600 = ' '.join(word_list_600)\n",
    "word800 = ' '.join(word_list_800)\n",
    "word900 = ' '.join(word_list_900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725c2c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize data\n",
    "labeled_documents = [(word100, [\"철학\"]),\n",
    "                     (word200, [\"종교\"]),\n",
    "                     (word300, [\"사회과학\"]),\n",
    "                     (word400, [\"자연과학\"]),\n",
    "                     (word500, [\"기술과학\"]),\n",
    "                     (word600, [\"예술\"]),\n",
    "                     (word800, [\"문학\"]),\n",
    "                     (word900, [\"역사\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2331bb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "llda_model = llda.LldaModel(labeled_documents=labeled_documents, alpha_vector=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb930e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "# llda_model.training(iteration=10, log=True)\n",
    "while True:\n",
    "    print(\"iteration %s sampling...\" % (llda_model.iteration + 1))\n",
    "    llda_model.training(1)\n",
    "    print(\"after iteration: %s, perplexity: %s\" % (llda_model.iteration, llda_model.perplexity()))\n",
    "    print(\"delta beta: %s\" % llda_model.delta_beta)\n",
    "    if llda_model.is_convergent(method=\"beta\", delta=0.5):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1eb1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training한 L-LDA 모델 저장\n",
    "with open('model_llda_2.pickle','wb') as fw:\n",
    "    pickle.dump(llda_model, fw)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
